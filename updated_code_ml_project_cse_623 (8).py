# -*- coding: utf-8 -*-
"""updated code ML Project CSE 623

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cqjdBp6QgZzttl-kE7ObgMQGEOtJcS0B
"""

# ðŸ“¦ Import required libraries
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# ðŸ“¥ Load your dataset
df = pd.read_csv("/content/drive/MyDrive/ML MODEL 1st raw file.csv")
df.columns = df.columns.str.strip()  # Clean column names


# âœ… Keep only numeric columns for correlation
numeric_df = df.select_dtypes(include=['int64', 'float64'])

# ðŸ“Š Plot heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title("ðŸ” Correlation Heatmap (Without Infill Pattern)")
plt.tight_layout()
plt.show()

# Import necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, RandomForestRegressor
import xgboost as xgb

# Load dataset
df = pd.read_csv("//content/drive/MyDrive/ML MODEL 1st raw file.csv")  # Ensure correct file path

# Define target column
target_column = "Tensile_strength"  # Update based on dataset

# Check if the target column exists
if target_column not in df.columns:
    print("Available Columns:", df.columns.tolist())
    raise ValueError(f"Target column '{target_column}' not found in dataset!")

# Ensure 'Elongation' and 'Roughness' are not included
columns_to_remove = ["Elongation", "Roughness"]
df = df.drop(columns=[col for col in columns_to_remove if col in df.columns], errors="ignore")
from sklearn.preprocessing import LabelEncoder

# Initialize LabelEncoder
label_encoder = LabelEncoder()

# Convert 'Material' to numeric before dropping other non-numeric columns
df["Material"] = label_encoder.fit_transform(df["Material"])  # PLA -> 0, ABS -> 1

# Drop non-numeric columns except 'Material'
df = df.select_dtypes(include=[np.number])

# Ensure target column is still present after dropping
if target_column not in df.columns:
    raise ValueError(f"After dropping non-numeric columns, '{target_column}' is missing!")

# Handle missing values
df.fillna(df.mean(), inplace=True)

# Split features and target
X = df.drop(columns=[target_column])
y = df[target_column]

# Split dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize models
models = {
    "Linear Regression": LinearRegression(),
    "AdaBoost Regression": AdaBoostRegressor(n_estimators=40, random_state=42),
    "XGBoost Regression": xgb.XGBRegressor(objective="reg:squarederror", n_estimators=40),
    "Gradient Boosting Regression": GradientBoostingRegressor(n_estimators=40, random_state=42),
    "Random Forest Regression": RandomForestRegressor(n_estimators=40, random_state=42)
}

# Train and evaluate models
results = {}
for name, model in models.items():
    model.fit(X_train, y_train)  # Train the model

    # Predictions on training and testing datasets
    y_pred_train = model.predict(X_train)
    y_pred_test = model.predict(X_test)

    # Compute RÂ² scores
    r2_train = r2_score(y_train, y_pred_train)
    r2_test = r2_score(y_test, y_pred_test)

    # Compute Mean Squared Error (MSE)
    mse_train = mean_squared_error(y_train, y_pred_train)
    mse_test = mean_squared_error(y_test, y_pred_test)

    # Store results
    results[name] = {
        "R2 Train": r2_train,
        "R2 Test": r2_test,
        "MSE Train": mse_train,
        "MSE Test": mse_test
    }

    # Print results
    print(f"{name} - RÂ² (Train): {r2_train:.4f}, RÂ² (Test): {r2_test:.4f}")
    print(f"{name} - MSE (Train): {mse_train:.4f}, MSE (Test): {mse_test:.4f}\n")

from google.colab import files

# Your trained model (assumes itâ€™s in memory)
rf_model = models["Random Forest Regression"]

# Load the new dataset (removed duplicate header row)
data = """layer_height	wall_thickness	infill_density	nozzle_temperature	Bed_temperature	Print_speed	Material	Fan_speed	Tensile Strength
0.2	1.2	35	232.5	95	47.5	ABS	100
0.3	0.8	50	240	80	65	ABS	100
0.2	1.2	20	232.5	95	47.5	ABS	100
0.1	0.8	50	225	110	30	ABS	100
0.3	1.2	35	232.5	95	47.5	ABS	100
0.2	1.2	35	232.5	95	47.5	ABS	100
0.2	1.2	35	232.5	95	47.5	ABS	100
0.2	1.2	50	232.5	95	47.5	ABS	100
0.1	1.2	35	232.5	110	30	ABS	100
0.3	1.6	20	240	110	30	ABS	100
0.1	1.6	50	240	80	47.5	ABS	100
0.3	0.8	50	240	95	30	ABS	100
0.3	1.6	50	240	80	30	ABS	100
0.2	1.2	35	240	95	47.5	ABS	100
0.2	1.2	35	240	80	30	ABS	100
0.1	0.8	50	240	80	65	ABS	100
0.1	0.8	50	240	110	30	ABS	100
0.1	1.6	20	240	110	65	ABS	100
0.3	1.6	20	240	95	30	ABS	100
0.3	1.2	35	240	80	30	ABS	100
0.3	1.6	20	240	80	30	ABS	100
0.1	0.8	50	240	110	30	ABS	100
0.2	1.2	35	232.5	95	47.5	ABS	100
0.2	1.2	35	232.5	110	47.5	ABS	100
0.2	1.2	35	225	95	47.5	ABS	100
0.3	0.8	50	232.5	110	65	ABS	100
0.1	1.6	50	232.5	110	65	ABS	100
0.2	1.6	35	225	95	30	ABS	100
0.1	1.6	50	225	110	30	ABS	100
0.1	1.2	20	225	80	30	ABS	100
0.3	0.8	20	225	80	30	ABS	100
0.2	1.2	35	232.5	95	47.5	ABS	100
0.2	1.2	35	232.5	95	47.5	ABS	100
0.215	1.2	35	205	95	52.5	PLA	100
0.215	1.2	35	205	80	52.5	PLA	100
0.215	1.2	35	205	95	52.5	PLA	100
0.215	1.2	35	205	110	52.5	PLA	100
0.215	1.2	35	205	95	52.5	PLA	100
0.215	1.2	35	205	95	52.5	PLA	100
0.33	1.2	35	190	95	40	PLA	100
0.33	0.8	50	190	95	40	PLA	100
0.215	0.8	50	205	110	52.5	PLA	100
0.1	1.2	50	190	110	52.5	PLA	100
0.215	1.6	20	205	80	40	PLA	100
0.33	1.6	50	220	95	52.5	PLA	100
0.1	1.6	50	205	80	40	PLA	100
0.1	0.8	50	205	95	52.5	PLA	100
0.215	1.2	35	205	80	52.5	PLA	100
0.215	1.2	35	205	80	40	PLA	100
0.1	1.6	50	190	110	52.5	PLA	100
0.33	1.6	50	190	110	40	PLA	100
0.215	1.2	35	205	95	65	PLA	100
0.1	0.8	50	205	80	65	PLA	100
0.215	1.6	50	220	80	40	PLA	100
0.33	1.6	35	220	110	52.5	PLA	100
0.215	0.8	50	205	95	52.5	PLA	100
0.215	1.2	35	220	110	65	PLA	100
0.215	1.6	20	220	95	52.5	PLA	100
0.33	1.6	50	190	110	65	PLA	100
"""

# Convert the string data to a DataFrame
df_new = pd.read_csv(StringIO(data), sep='\t')
df_new.columns = df_new.columns.str.strip()  # Clean column names

# Debug: Check initial DataFrame
print("Initial df_new columns:", df_new.columns.tolist())
print("Initial df_new dtypes:\n", df_new.dtypes)

# Convert numeric columns explicitly
numeric_cols = ['layer_height', 'wall_thickness', 'infill_density', 'nozzle_temperature',
                'Bed_temperature', 'Print_speed', 'Fan_speed']
df_new[numeric_cols] = df_new[numeric_cols].apply(pd.to_numeric, errors='coerce')

# Preprocess the new dataset
label_encoder = LabelEncoder()
df_new["Material"] = label_encoder.fit_transform(df_new["Material"])  # ABS -> 1, PLA -> 0

# Select only the features used in training (exclude 'Tensile Strength')
X_new = df_new.drop(columns=["Tensile Strength"]).select_dtypes(include=[np.number])

# Debug: Check X_new columns and dtypes
print("X_new columns after preprocessing:", X_new.columns.tolist())
print("X_new dtypes:\n", X_new.dtypes)

# Get the feature names the model was trained on
expected_features = rf_model.feature_names_in_
print("Features expected by the model:", expected_features)

# Ensure X_new matches the expected features
X_new = X_new[expected_features]  # Reorder and select only the expected columns

# Predict tensile strength using the trained Random Forest model
predictions = rf_model.predict(X_new)

# Add predictions to the DataFrame
df_new["Predicted_Tensile_Strength"] = predictions

# Display the first 5 predictions
print("\nFirst 5 predictions:")
print(df_new[['layer_height', 'wall_thickness', 'infill_density', 'nozzle_temperature',
              'Bed_temperature', 'Print_speed', 'Material', 'Predicted_Tensile_Strength']].head())

# Save the results to a CSV file
output_file = 'tensile_strength_predictions_new.csv'
df_new.to_csv(output_file, index=False)

print(f"\nPredictions have been saved to '{output_file}'")
print("You can download this file containing all features and predicted tensile strength values.")

# Download the file in Colab
files.download(output_file)

# Load dataset
df = pd.read_csv("/content/drive/MyDrive/ML MODEL (kaggle + research paper).csv")  # Ensure correct file path

# Define target column
target_column = "Tensile_strength"  # Update based on dataset

# Check if the target column exists
if target_column not in df.columns:
    print("Available Columns:", df.columns.tolist())
    raise ValueError(f"Target column '{target_column}' not found in dataset!")

# Ensure 'Elongation' and 'Roughness' are not included
columns_to_remove = ["Elongation", "Roughness"]
df = df.drop(columns=[col for col in columns_to_remove if col in df.columns], errors="ignore")
from sklearn.preprocessing import LabelEncoder

# Initialize LabelEncoder
label_encoder = LabelEncoder()

# Convert 'Material' to numeric before dropping other non-numeric columns
df["Material"] = label_encoder.fit_transform(df["Material"])  # PLA -> 0, ABS -> 1

# Drop non-numeric columns except 'Material'
df = df.select_dtypes(include=[np.number])

# Ensure target column is still present after dropping
if target_column not in df.columns:
    raise ValueError(f"After dropping non-numeric columns, '{target_column}' is missing!")

# Handle missing values
df.fillna(df.mean(), inplace=True)

# Split features and target
X = df.drop(columns=[target_column])
y = df[target_column]

# Split dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize models
models = {
    "Linear Regression": LinearRegression(),
    "AdaBoost Regression": AdaBoostRegressor(n_estimators=40, random_state=42),
    "XGBoost Regression": xgb.XGBRegressor(objective="reg:squarederror", n_estimators=40),
    "Gradient Boosting Regression": GradientBoostingRegressor(n_estimators=40, random_state=42),
    "Random Forest Regression": RandomForestRegressor(n_estimators=40, random_state=42)
}

# Train and evaluate models
results = {}
for name, model in models.items():
    model.fit(X_train, y_train)  # Train the model

    # Predictions on training and testing datasets
    y_pred_train = model.predict(X_train)
    y_pred_test = model.predict(X_test)

    # Compute RÂ² scores
    r2_train = r2_score(y_train, y_pred_train)
    r2_test = r2_score(y_test, y_pred_test)

    # Compute Mean Squared Error (MSE)
    mse_train = mean_squared_error(y_train, y_pred_train)
    mse_test = mean_squared_error(y_test, y_pred_test)

    # Store results
    results[name] = {
        "R2 Train": r2_train,
        "R2 Test": r2_test,
        "MSE Train": mse_train,
        "MSE Test": mse_test
    }

    # Print results
    print(f"{name} - RÂ² (Train): {r2_train:.4f}, RÂ² (Test): {r2_test:.4f}")
    print(f"{name} - MSE (Train): {mse_train:.4f}, MSE (Test): {mse_test:.4f}\n")

import matplotlib.pyplot as plt
import numpy as np

# Models
models = ['Linear Regression', 'AdaBoost', 'XGBoost', 'Gradient Boosting', 'Random Forest']

# RÂ² scores
r2_kaggle = [0.6423, 0.603, 0.6589, 0.7062, 0.7891]
r2_paper = [0.6785, 0.7719, 0.8042, 0.8734, 0.8152]

# MSE scores
mse_kaggle = [21.5732, 23.9409, 20.5727, 17.7187, 12.7192]
mse_paper = [17.5779, 12.4723, 10.7058, 6.9228, 10.1049]

x = np.arange(len(models))
width = 0.35

# Plotting
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))

# RÂ² Plot
ax1.bar(x - width/2, r2_kaggle, width, label='Kaggle Data', color='#1f77b4')
ax1.bar(x + width/2, r2_paper, width, label='Research Paper Data', color='#ff7f0e')
ax1.set_ylabel('RÂ² Score')
ax1.set_title('Model Comparison - RÂ² Score')
ax1.set_xticks(x)
ax1.set_xticklabels(models, rotation=45)
ax1.legend()
ax1.grid(True, linestyle='--', alpha=0.5)

# MSE Plot
ax2.bar(x - width/2, mse_kaggle, width, label='Kaggle Data', color='#2ca02c')
ax2.bar(x + width/2, mse_paper, width, label='Research Paper Data', color='#d62728')
ax2.set_ylabel('Mean Squared Error')
ax2.set_title('Model Comparison - MSE')
ax2.set_xticks(x)
ax2.set_xticklabels(models, rotation=45)
ax2.legend()
ax2.grid(True, linestyle='--', alpha=0.5)

plt.tight_layout()
plt.show()

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, cross_validate
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, RandomForestRegressor
import xgboost as xgb
from sklearn.metrics import make_scorer, mean_squared_error

# --- Assume your dataset has been loaded and preprocessed ---
# For example, assuming you have your final dataset in variables X and y:
# X: A DataFrame containing features.
# y: A Series containing the target variable "Tensile_strength".

# Here we mock up some data to simulate the situation:
# (Replace this with your actual data loading code)
# -----------------------------------------------------------
np.random.seed(42)
X = pd.DataFrame(np.random.rand(200, 5), columns=['layer_height', 'wall_thickness', 'infill_density',
                                                  'nozzle_temperature', 'print_speed'])
y = X['layer_height'] * 50 + X['wall_thickness'] * 30 + np.random.randn(200) * 5
# -----------------------------------------------------------

# Optionally split the dataset (or use full data for CV)
# Here we use the entire dataset for cross-validation.
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the models in a dictionary.
# Each model will be coupled with a Pipeline containing imputation and scaling.
models = {
    "Linear Regression": Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='mean')),
        ('scaler', StandardScaler()),
        ('model', LinearRegression())
    ]),
    "AdaBoost Regression": Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='mean')),
        ('scaler', StandardScaler()),
        ('model', AdaBoostRegressor(random_state=42))
    ]),
    "XGBoost Regression": Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='mean')),
        ('scaler', StandardScaler()),
        ('model', xgb.XGBRegressor(objective="reg:squarederror", random_state=42))
    ]),
    "Gradient Boosting Regression": Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='mean')),
        ('scaler', StandardScaler()),
        ('model', GradientBoostingRegressor(random_state=42))
    ]),
    "Random Forest Regression": Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='mean')),
        ('scaler', StandardScaler()),
        ('model', RandomForestRegressor(random_state=42))
    ])
}

# Define scoring metrics
scoring = {
    'r2': 'r2',
    'mse': make_scorer(mean_squared_error)
}

# Dictionary to collect cross-validation results for each model
cv_results = {}

# Perform 5-fold cross-validation for each model
for name, pipeline in models.items():
    print(f"\nRunning 5-Fold CV for: {name}")
    results = cross_validate(pipeline, X, y, cv=5, scoring=scoring, return_train_score=True)
    cv_results[name] = results

    print(f"Average Train RÂ²: {np.mean(results['train_r2']):.4f}")
    print(f"Average Test RÂ²:  {np.mean(results['test_r2']):.4f}")
    print(f"Average Train MSE: {np.mean(results['train_mse']):.4f}")
    print(f"Average Test MSE:  {np.mean(results['test_mse']):.4f}")

# Optionally, convert the results to a summary DataFrame
results_summary = []
for model_name, metrics in cv_results.items():
    summary = {
        "Model": model_name,
        "Train RÂ²": np.mean(metrics['train_r2']),
        "Test RÂ²": np.mean(metrics['test_r2']),
        "Train MSE": np.mean(metrics['train_mse']),
        "Test MSE": np.mean(metrics['test_mse'])
    }
    results_summary.append(summary)

results_df = pd.DataFrame(results_summary)
print("\nSummary of 5-Fold Cross Validation Results:")
print(results_df)

import matplotlib.pyplot as plt
import pandas as pd

# Comparison Data
data = {
    'Model': [
        'Linear Regression', 'AdaBoost Regression', 'XGBoost Regression',
        'Gradient Boosting Regression', 'Random Forest Regression'
    ],
    'Test RÂ² (No CV)': [0.6785, 0.7719, 0.8042, 0.8734, 0.8111],
    'Test RÂ² (CV)': [0.9181, 0.8822, 0.8649, 0.8761, 0.8761],
    'Test MSE (No CV)': [17.5779, 12.4723, 10.7058, 6.9228, 10.3271],
    'Test MSE (CV)': [23.7128, 33.9169, 39.0028, 35.7538, 35.9617]
}

df = pd.DataFrame(data)

# RÂ² Comparison Plot
plt.figure(figsize=(10, 5))
x = range(len(df))
plt.bar([i - 0.2 for i in x], df['Test RÂ² (No CV)'], width=0.4, label='Test RÂ² (No CV)', color='skyblue')
plt.bar([i + 0.2 for i in x], df['Test RÂ² (CV)'], width=0.4, label='Test RÂ² (CV)', color='orange')
plt.xticks(x, df['Model'], rotation=20)
plt.ylabel("RÂ² Score")
plt.title("Comparison of Test RÂ² with and without Cross-Validation")
plt.legend()
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

# MSE Comparison Plot
plt.figure(figsize=(10, 5))
plt.bar([i - 0.2 for i in x], df['Test MSE (No CV)'], width=0.4, label='Test MSE (No CV)', color='lightcoral')
plt.bar([i + 0.2 for i in x], df['Test MSE (CV)'], width=0.4, label='Test MSE (CV)', color='seagreen')
plt.xticks(x, df['Model'], rotation=20)
plt.ylabel("Mean Squared Error")
plt.title("Comparison of Test MSE with and without Cross-Validation")
plt.legend()
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor
from sklearn.inspection import permutation_importance
from sklearn.metrics import r2_score
import xgboost as xgb
import matplotlib.pyplot as plt
import seaborn as sns

# 1. Load dataset
df = pd.read_csv("/content/drive/MyDrive/ML MODEL (kaggle + research paper).csv")

# 2. Drop unwanted columns
df = df.drop(columns=[col for col in ["Elongation", "Roughness"] if col in df.columns], errors='ignore')

# 3. Encode 'Material' column
label_encoder = LabelEncoder()
df['Material'] = label_encoder.fit_transform(df['Material'])  # PLA = 0, ABS = 1

# 4. Keep only numeric columns
df = df.select_dtypes(include=[np.number])
df.fillna(df.mean(), inplace=True)

# 5. Split features and target
target_column = "Tensile_strength"
X = df.drop(columns=[target_column])
y = df[target_column]
features = X.columns.tolist()

# 6. Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 7. Define models
models = {
    "Random Forest": RandomForestRegressor(n_estimators=100, random_state=42),
    "Gradient Boosting": GradientBoostingRegressor(n_estimators=100, random_state=42),
    "AdaBoost": AdaBoostRegressor(n_estimators=100, random_state=42),
    "XGBoost": xgb.XGBRegressor(n_estimators=100, objective='reg:squarederror', random_state=42)
}

# 8. Collect permutation importances
importance_all = []

for model_name, model in models.items():
    model.fit(X_train, y_train)
    result = permutation_importance(
        model, X_test, y_test,
        n_repeats=10,
        random_state=42,
        n_jobs=-1
    )
    for i, feat in enumerate(features):
        importance_all.append({
            "Feature": feat,
            "Importance": result.importances_mean[i],
            "Model": model_name
        })

# 9. Create a DataFrame for plotting
df_importance = pd.DataFrame(importance_all)

# Normalize feature order based on average importance
feature_order = df_importance.groupby("Feature")["Importance"].mean().sort_values(ascending=False).index


# 10. Plot grouped bar chart
plt.figure(figsize=(14, 7), dpi=300)  # <-- Added dpi=500 for high-resolution output
sns.barplot(data=df_importance, x="Importance", y="Feature", hue="Model", order=feature_order, palette="Set2")
plt.title("Permutation Feature Importance Across Models")
plt.xlabel("Mean Importance Decrease")
plt.ylabel("Feature")
plt.legend(title="Model")
plt.grid(axis='x', linestyle='--', alpha=0.6)
plt.tight_layout()
plt.show()

# --- Imports ---
import numpy as np
import ipywidgets as widgets
from IPython.display import display, clear_output

# --- Prerequisites ---
# X: DataFrame with labelâ€‘encoded Material (0/1)
# models: {
#   "Random Forest Regression": rf_model,
#   "Gradient Boosting Regression": gb_model
# }

# Define the models again with correct keys expected by the widget UI
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor

models = {
    "Random Forest Regression": RandomForestRegressor(n_estimators=100, random_state=42),
    "Gradient Boosting Regression": GradientBoostingRegressor(n_estimators=100, random_state=42)
}

# Train them again (or reuse trained models if available)
models["Random Forest Regression"].fit(X_train, y_train)
models["Gradient Boosting Regression"].fit(X_train, y_train)



feature_names = list(X.columns)
numeric_feats = [f for f in feature_names if f != "Material"]

# 1) Hardâ€‘coded Material dropdown
material_map = {"PLA": 0, "ABS": 1}
material_dropdown = widgets.Dropdown(
    options=list(material_map.keys()),
    description="Material:"
)

# 2) Numeric inputs
numeric_widgets = {
    feat: widgets.FloatText(
        description=feat.replace("_"," ").title()+":",
        value=float(X[feat].mean()),
        step=0.1
    )
    for feat in numeric_feats
}

# 3) Wide, highlighted Predict button + output
predict_btn = widgets.Button(
    description="Predict Tensile Strength",
    button_style='success',    # green
    tooltip="Click to predict tensile strength using both models",
    layout=widgets.Layout(width='300px')   # adjust width here
)
output = widgets.Output()

# 4) Callback
def on_predict(b):
    with output:
        clear_output()
        # Map label to code
        mat_code = material_map[material_dropdown.value]

        # Build feature vector
        vals = [mat_code] + [numeric_widgets[f].value for f in numeric_feats]
        arr  = np.array(vals).reshape(1, -1)

        # Predictions
        rf_p = models["Random Forest Regression"].predict(arr)[0]
        gb_p = models["Gradient Boosting Regression"].predict(arr)[0]

        # Display only the predictions
        print(f"Random Forest Prediction:     {rf_p:.4f}")
        print(f"Gradient Boosting Prediction: {gb_p:.4f}")

predict_btn.on_click(on_predict)

# 5) Layout & display
ui = widgets.VBox(
    [material_dropdown]
    + [numeric_widgets[f] for f in numeric_feats]
    + [predict_btn]
)
display(ui, output)

import numpy as np

y_pred_rf = models["Random Forest Regression"].predict(X_test)
residuals = y_test - y_pred_rf  # Difference between actual and predicted

plt.figure(figsize=(8, 5))
sns.scatterplot(x=y_pred_rf, y=residuals)
plt.axhline(y=0, color='r', linestyle='--')
plt.xlabel("Predicted Values")
plt.ylabel("Residuals")
plt.title("Residual Plot - Random Forest")
plt.show()

# --- Full Updated Code for GridSearchCV Including AdaBoost & XGBoost ---

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
import pandas as pd

# --- Updated Parameter Grids ---
param_grids = {
    "Random Forest Regression": {
        'n_estimators': [50, 100, 200],
        'max_depth': [None, 10, 20],
        'min_samples_split': [2, 5]
    },
    "Gradient Boosting Regression": {
        'n_estimators': [50, 100, 200],
        'learning_rate': [0.01, 0.1, 0.2],
        'max_depth': [3, 5, 7]
    },
    "AdaBoost Regression": {
        'n_estimators': [50, 100, 200],
        'learning_rate': [0.01, 0.1, 1.0]
    },
    "XGBoost Regression": {
        'n_estimators': [50, 100, 200],
        'learning_rate': [0.01, 0.1, 0.2],
        'max_depth': [3, 5, 7]
    }
}

# --- Containers ---
best_models = {}
results = {}

# --- GridSearchCV for All Models ---
for name, model in models.items():
    print(f"\n\U0001F3F7ï¸  Model: {name}")
    if name in param_grids:
        print(f"   \U0001F50D Performing GridSearchCV for {name}...")
        grid = GridSearchCV(
            estimator=model,
            param_grid=param_grids[name],
            cv=3,
            scoring='neg_mean_squared_error',
            n_jobs=-1,
            verbose=1
        )
        grid.fit(X_train, y_train)
        best_model = grid.best_estimator_
        best_params = grid.best_params_
        print(f"   âœ… Best Params: {best_params}")
    else:
        print("   âš ï¸ No grid defined â€” training with default hyperparameters")
        best_model = model.fit(X_train, y_train)
        best_params = {}

    best_models[name] = best_model

    # Evaluate
    y_pred_train = best_model.predict(X_train)
    y_pred_test = best_model.predict(X_test)

    results[name] = {
        "Best Params": best_params,
        "R2 Train": r2_score(y_train, y_pred_train),
        "R2 Test": r2_score(y_test, y_pred_test),
        "MSE Train": mean_squared_error(y_train, y_pred_train),
        "MSE Test": mean_squared_error(y_test, y_pred_test)
    }

    print(f"   \U0001F4CA RÂ² (Train/Test): {results[name]['R2 Train']:.4f} / {results[name]['R2 Test']:.4f}")
    print(f"   \U0001F4C9 MSE (Train/Test): {results[name]['MSE Train']:.4f} / {results[name]['MSE Test']:.4f}")

from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint, uniform
from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, RandomForestRegressor
import xgboost as xgb
models = {
    "AdaBoost Regression": AdaBoostRegressor(random_state=42),
    "XGBoost Regression": xgb.XGBRegressor(objective='reg:squarederror', random_state=42),
    "Gradient Boosting Regression": GradientBoostingRegressor(random_state=42),
    "Random Forest Regression": RandomForestRegressor(random_state=42)
}

param_dists = {
    "AdaBoost Regression": {
        'n_estimators': randint(50, 200),
        'learning_rate': uniform(0.01, 0.3)
    },
    "XGBoost Regression": {
        'n_estimators': randint(50, 200),
        'learning_rate': uniform(0.01, 0.3),
        'max_depth': randint(3, 10)
    },
    "Gradient Boosting Regression": {
        'n_estimators': randint(50, 200),
        'learning_rate': uniform(0.01, 0.3),
        'max_depth': randint(3, 10)
    },
    "Random Forest Regression": {
        'n_estimators': randint(50, 200),
        'max_depth': [None, 10, 20, 30],
        'min_samples_split': randint(2, 10),
        'min_samples_leaf': randint(1, 5)
    }
}
from sklearn.metrics import mean_squared_error, r2_score

results = {}

for name, model in models.items():
    print(f"\nðŸ” Tuning {name} using RandomizedSearchCV...")

    search = RandomizedSearchCV(
        estimator=model,
        param_distributions=param_dists[name],
        n_iter=10,
        cv=3,
        scoring='neg_mean_squared_error',
        n_jobs=-1,
        random_state=42
    )

    search.fit(X_train, y_train)
    best_model = search.best_estimator_
    y_pred = best_model.predict(X_test)

    results[name] = {
        "Best Params": search.best_params_,
        "R2 Score": r2_score(y_test, y_pred),
        "MSE": mean_squared_error(y_test, y_pred)
    }

    print(f"âœ… Best Params: {search.best_params_}")
    print(f"ðŸ“ˆ RÂ² Score: {results[name]['R2 Score']:.4f}")
    print(f"ðŸ“‰ MSE: {results[name]['MSE']:.2f}")
import pandas as pd

summary_df = pd.DataFrame(results).T
print("\nðŸ“Š Summary of RandomizedSearchCV Results:")
display(summary_df)

import matplotlib.pyplot as plt
import pandas as pd

# Data
data = {
    "Model": ["AdaBoost", "Gradient Boosting", "Random Forest", "XGBoost"],
    "Before Tuning": [0.7719, 0.8734, 0.8111, 0.8042],
    "After Tuning (GridSearchCV)": [0.7741, 0.8251, 0.8278, 0.8825],
    "After Tuning (RandomizedSearchCV)": [0.779, 0.906966, 0.796391, 0.878691],
}
df = pd.DataFrame(data)

# Plot and Save
plt.figure(figsize=(10, 6))
x = range(len(df["Model"]))
bar_width = 0.25

plt.bar([i - bar_width for i in x], df["Before Tuning"], width=bar_width, label='Before Tuning', color='lightcoral')
plt.bar(x, df["After Tuning (GridSearchCV)"], width=bar_width, label='After GridSearchCV', color='skyblue')
plt.bar([i + bar_width for i in x], df["After Tuning (RandomizedSearchCV)"], width=bar_width, label='After RandomizedSearchCV', color='mediumseagreen')

plt.xticks(x, df["Model"])
plt.ylabel("RÂ² Score")
plt.title("RÂ² Score Comparison: Before vs After Hyperparameter Tuning")
plt.ylim(0.75, 1.0)
plt.legend()
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.savefig("r2_comparison_before_after_tuning.png")  # Saves locally
plt.show()

from google.colab import files
files.download("Grid_vs_Random_Search_Comparison.xlsx")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Data for MSE comparison (Before & After Tuning)
data = {
    'Model': ['AdaBoost', 'XGBoost', 'Gradient Boosting', 'Random Forest'],
    'Before Tuning': [12.4723, 10.7058,6.9228, 10.3271],  # MSE before tuning
    'GridSearchCV': [12.3495, 6.4257, 9.5616, 9.4160],     # MSE after GridSearchCV
    'RandomizedSearchCV': [12.0794, 6.6319, 5.0861, 11.1311]  # MSE after RandomizedSearchCV
}

# Create DataFrame and melt for plotting
df = pd.DataFrame(data)
df_melted = df.melt(id_vars='Model', var_name='Tuning Method', value_name='MSE')

# Plot MSE comparison
plt.figure(figsize=(10, 6))
sns.barplot(data=df_melted, x='Model', y='MSE', hue='Tuning Method')
plt.title('MSE Comparison: Before & After Hyperparameter Tuning')
plt.ylabel('Mean Squared Error (MSE)')
plt.xlabel('Regression Model')
plt.xticks(rotation=20)
plt.ylim(0, max(df_melted['MSE']) + 2)
plt.tight_layout()
plt.show()

rf_model = models["Random Forest Regression"]

# ðŸ” Retrain if needed
rf_model.fit(X_train, y_train)

import shap
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Use a sample of X_test for SHAP computation (if X_test is large)
X_sample = X_test if X_test.shape[0] < 100 else X_test.iloc[:100, :]

# Create a list to store SHAP results for each model (as a DataFrame)
shap_df_list = []

# Loop through your models and compute SHAP values
for name, model in models.items():
    print(f"Computing SHAP values for: {name}")

    # Select an appropriate SHAP explainer
    if name == "Linear Regression":
        explainer = shap.LinearExplainer(model, X_sample, feature_perturbation="interventional")
    elif name == "AdaBoost Regression":
        # For AdaBoost, TreeExplainer may not be supported so we use KernelExplainer
        explainer = shap.KernelExplainer(model.predict, X_sample)
    else:
        explainer = shap.TreeExplainer(model)

    # Compute SHAP values for the sample
    shap_values = explainer.shap_values(X_sample)

    # Convert the SHAP matrix into a DataFrame
    # Resulting DataFrame will have columns corresponding to features and each row a sample's SHAP values
    temp_df = pd.DataFrame(shap_values, columns=X_sample.columns)

    # Melt the DataFrame to have one row per feature per sample
    temp_df = temp_df.melt(var_name="Feature", value_name="SHAP_Value")
    temp_df["Method"] = name  # Append the model's name
    shap_df_list.append(temp_df)

# Combine all SHAP data into a single DataFrame
combined_shap_df = pd.concat(shap_df_list, ignore_index=True)

# -----------------------------------
# 1. Bar Graph: Mean Absolute SHAP Values per Feature by Method
# -----------------------------------
# Compute mean absolute SHAP value per feature for each method
bar_data = combined_shap_df.copy()
bar_data["Abs_SHAP"] = bar_data["SHAP_Value"].abs()
mean_abs = bar_data.groupby(["Method", "Feature"], as_index=False)["Abs_SHAP"].mean()

plt.figure(figsize=(12, 8))
sns.barplot(data=mean_abs, x="Feature", y="Abs_SHAP", hue="Method")
plt.title("Mean Absolute SHAP Value per Feature by Method")
plt.ylabel("Mean |SHAP Value|")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# -----------------------------------
# 2. Summary Chart: Distribution of SHAP Values per Feature (Box Plot)
# -----------------------------------
plt.figure(figsize=(12, 8))
sns.boxplot(data=combined_shap_df, x="Feature", y="SHAP_Value", hue="Method")
plt.title("SHAP Value Distribution per Feature by Method")
plt.ylabel("SHAP Value")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

